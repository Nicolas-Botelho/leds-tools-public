"use strict";(self.webpackChunkdocumentacao_leds_tools=self.webpackChunkdocumentacao_leds_tools||[]).push([[8916],{1857:(e,o,n)=>{n.r(o),n.d(o,{assets:()=>d,contentTitle:()=>l,default:()=>p,frontMatter:()=>a,metadata:()=>s,toc:()=>r});var t=n(4848),i=n(8453);const a={sidebar_position:3,title:"How to Support a New LLM",description:"A guide to integrate a different Language Model like a local one via Ollama"},l="How to Support a New LLM (e.g., via Ollama)",s={id:"code_wise/code_wise_lib/Advanced_Concepts/llms",title:"How to Support a New LLM",description:"A guide to integrate a different Language Model like a local one via Ollama",source:"@site/docs/code_wise/code_wise_lib/2_Advanced_Concepts/llms.md",sourceDirName:"code_wise/code_wise_lib/2_Advanced_Concepts",slug:"/code_wise/code_wise_lib/Advanced_Concepts/llms",permalink:"/leds-tools-public/code_wise/code_wise_lib/Advanced_Concepts/llms",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3,title:"How to Support a New LLM",description:"A guide to integrate a different Language Model like a local one via Ollama"},sidebar:"code_wise",previous:{title:"Workflow Breakdown",permalink:"/leds-tools-public/code_wise/code_wise_lib/Advanced_Concepts/workflow-breakdown"},next:{title:"Design Concept - Git Hooks",permalink:"/leds-tools-public/code_wise/code_wise_lib/Advanced_Concepts/design-concept-git-hooks"}},d={},r=[{value:"1. Update the Configuration (<code>.env</code>)",id:"1-update-the-configuration-env",level:3},{value:"2. Modify the AI Core (<code>codewise_lib/crew.py</code>)",id:"2-modify-the-ai-core-codewise_libcrewpy",level:3},{value:"3. Update the Documentation",id:"3-update-the-documentation",level:3}];function c(e){const o={code:"code",h1:"h1",h3:"h3",header:"header",p:"p",pre:"pre",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(o.header,{children:(0,t.jsx)(o.h1,{id:"how-to-support-a-new-llm-eg-via-ollama",children:"How to Support a New LLM (e.g., via Ollama)"})}),"\n",(0,t.jsx)(o.p,{children:"CodeWise can be extended to support different LLMs, such as local models running through Ollama. This allows for offline use, cost reduction, and enhanced data privacy."}),"\n",(0,t.jsxs)(o.h3,{id:"1-update-the-configuration-env",children:["1. Update the Configuration (",(0,t.jsx)(o.code,{children:".env"}),")"]}),"\n",(0,t.jsxs)(o.p,{children:["The first step is to allow the user to choose their LLM provider. This can be done by adding a new variable to the ",(0,t.jsx)(o.code,{children:".env"})," file:"]}),"\n",(0,t.jsx)(o.pre,{children:(0,t.jsx)(o.code,{className:"language-env",children:'# Options: "gemini" or "ollama"\r\nLLM_PROVIDER=ollama\r\n\r\n# Specify the local model to be used by Ollama\r\nOLLAMA_MODEL=llama3\n'})}),"\n",(0,t.jsxs)(o.h3,{id:"2-modify-the-ai-core-codewise_libcrewpy",children:["2. Modify the AI Core (",(0,t.jsx)(o.code,{children:"codewise_lib/crew.py"}),")"]}),"\n",(0,t.jsx)(o.p,{children:"In the Codewise class constructor, implement a factory logic that instantiates the correct LLM based on the environment variable. CrewAI has native support for Ollama, making this straightforward."}),"\n",(0,t.jsx)(o.pre,{children:(0,t.jsx)(o.code,{className:"language-python",children:'# At the beginning of the file\r\nfrom crewai_tools import Ollama\r\n\r\n# Inside the Codewise class __init__ method\r\nllm_provider = os.getenv("LLM_PROVIDER", "gemini")\r\n\r\nif llm_provider == "ollama":\r\n    ollama_model = os.getenv("OLLAMA_MODEL", "llama3")\r\n    # Assumes Ollama is running on the default local address\r\n    self.llm = Ollama(model=ollama_model)\r\nelse:\r\n    # The existing Gemini LLM instantiation\r\n    self.llm = LLM(model="gemini/gemini-2.0-flash", ...)\n'})}),"\n",(0,t.jsx)(o.h3,{id:"3-update-the-documentation",children:"3. Update the Documentation"}),"\n",(0,t.jsxs)(o.p,{children:["The installation guide must be updated to include instructions on how to install Ollama, download a model (e.g., ",(0,t.jsx)(o.code,{children:"ollama pull llama3"}),"), and configure the new variables in the ",(0,t.jsx)(o.code,{children:".env"})," file."]})]})}function p(e={}){const{wrapper:o}={...(0,i.R)(),...e.components};return o?(0,t.jsx)(o,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453:(e,o,n)=>{n.d(o,{R:()=>l,x:()=>s});var t=n(6540);const i={},a=t.createContext(i);function l(e){const o=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(o):{...o,...e}}),[o,e])}function s(e){let o;return o=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),t.createElement(a.Provider,{value:o},e.children)}}}]);